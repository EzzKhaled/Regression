{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('.')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Data Exploration and Understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from regression import load_california_houses_data\n",
        "X, y, feature_names = load_california_houses_data()\n",
        "print(\"California Housing Dataset Overview:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Dataset shape: {X.shape}\")\n",
        "print(f\"Number of features: {X.shape[1]}\")\n",
        "print(f\"Number of samples: {X.shape[0]}\")\n",
        "print(f\"Target range: ${y.min():.0f} - ${y.max():.0f}\")\n",
        "df = pd.DataFrame(X, columns=feature_names)\n",
        "df['Median_House_Value'] = y\n",
        "print(\"\\nFeature Statistics:\")\n",
        "print(df.describe().round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(4, 4, figsize=(16, 12))\n",
        "axes = axes.ravel()\n",
        "for i, feature in enumerate(feature_names[:13]):  \n",
        "    axes[i].hist(df[feature], bins=30, alpha=0.7, edgecolor='black')\n",
        "    axes[i].set_title(f'Distribution of {feature}')\n",
        "    axes[i].set_xlabel(feature)\n",
        "    axes[i].set_ylabel('Frequency')\n",
        "for i in range(len(feature_names), len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 10))\n",
        "correlation_matrix = df.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=0.5, fmt='.2f')\n",
        "plt.title('Feature Correlation Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"\\nTop correlations with Median House Value:\")\n",
        "corr_with_target = correlation_matrix['Median_House_Value'].sort_values(ascending=False)\n",
        "print(corr_with_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Run  Regression "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from regression import run_regression\n",
        "print(\"Running Complete Regression Analysis...\")\n",
        "print(\"=\" * 60)\n",
        "manual_results, sklearn_results, feature_names = run_regression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nCoefficient Comparison: Manual vs Scikit-Learn\")\n",
        "print(\"=\" * 55)\n",
        "feature_names_with_bias = ['Bias'] + feature_names\n",
        "manual_linear_coef = manual_results['linear']['coefficients']\n",
        "sklearn_linear_coef = sklearn_results['linear']['coefficients']\n",
        "coef_comparison = pd.DataFrame({\n",
        "    'Feature': feature_names_with_bias,\n",
        "    'Manual_Coefficient': manual_linear_coef,\n",
        "    'Sklearn_Coefficient': sklearn_linear_coef,\n",
        "    'Difference': np.abs(manual_linear_coef - sklearn_linear_coef)\n",
        "})\n",
        "print(\"\\nLinear Regression Coefficients Comparison:\")\n",
        "print(coef_comparison.round(6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "features_to_plot = min(8, len(feature_names))\n",
        "x_pos = np.arange(features_to_plot)\n",
        "width = 0.35\n",
        "plt.bar(x_pos - width/2, manual_linear_coef[1:features_to_plot+1], width,\n",
        "        label='Manual Implementation', alpha=0.7)\n",
        "plt.bar(x_pos + width/2, sklearn_linear_coef[1:features_to_plot+1], width,\n",
        "        label='Scikit-Learn', alpha=0.7)\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Coefficient Value')\n",
        "plt.title('Linear Regression Coefficients: Manual vs Scikit-Learn (First 8 Features)')\n",
        "plt.xticks(x_pos, feature_names[:features_to_plot], rotation=45, ha='right')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3, axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Regularization  Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nRegularization Effects on Coefficients\")\n",
        "print(\"=\" * 45)\n",
        "linear_coef = manual_results['linear']['coefficients'][1:8]  \n",
        "ridge_coef = manual_results['ridge']['coefficients'][1:8]\n",
        "lasso_coef = manual_results['lasso']['coefficients'][1:8]\n",
        "reg_comparison = pd.DataFrame({\n",
        "    'Feature': feature_names[:7],\n",
        "    'Linear': linear_coef,\n",
        "    f\"Ridge (α={manual_results['ridge']['best_alpha']})\": ridge_coef,\n",
        "    f\"Lasso (α={manual_results['lasso']['best_alpha']})\": lasso_coef\n",
        "})\n",
        "print(\"\\nCoefficient values across different regularization types (first 7 features):\")\n",
        "print(reg_comparison.round(6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "features_to_plot = min(7, len(feature_names))\n",
        "x_pos = np.arange(features_to_plot)\n",
        "width = 0.25\n",
        "plt.bar(x_pos - width, linear_coef, width, label='Linear (No Reg)', alpha=0.8)\n",
        "plt.bar(x_pos, ridge_coef, width, label=f'Ridge (α={manual_results[\"ridge\"][\"best_alpha\"]})', alpha=0.8)\n",
        "plt.bar(x_pos + width, lasso_coef, width, label=f'Lasso (α={manual_results[\"lasso\"][\"best_alpha\"]})', alpha=0.8)\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Coefficient Value')\n",
        "plt.title('Regularization Effects: Coefficient Comparison (First 7 Features)')\n",
        "plt.xticks(x_pos, feature_names[:features_to_plot], rotation=45, ha='right')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3, axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Performance Analysis "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "performance_data = []\n",
        "for model_type in ['linear', 'ridge', 'lasso']:\n",
        "    manual = manual_results[model_type]\n",
        "    sklearn = sklearn_results[model_type] \n",
        "    performance_data.append({\n",
        "        'Model': model_type.upper(),\n",
        "        'Implementation': 'Manual',\n",
        "        'MSE': manual['mse'],\n",
        "        'MAE': manual['mae'],\n",
        "        'R²': manual['r2']\n",
        "    })   \n",
        "    performance_data.append({\n",
        "        'Model': model_type.upper(),\n",
        "        'Implementation': 'Scikit-Learn',\n",
        "        'MSE': sklearn['mse'],\n",
        "        'MAE': sklearn['mae'],\n",
        "        'R²': sklearn['r2']\n",
        "    })\n",
        "performance_df = pd.DataFrame(performance_data)\n",
        "print(\"Comprehensive Performance Comparison\")\n",
        "print(\"=\" * 50)\n",
        "print(performance_df.round(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Key Findings "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"KEY FINDINGS AND INSIGHTS\")\n",
        "print(\"=\" * 40)\n",
        "mse_differences = []\n",
        "for model_type in ['linear', 'ridge', 'lasso']:\n",
        "    manual_mse = manual_results[model_type]['mse']\n",
        "    sklearn_mse = sklearn_results[model_type]['mse']\n",
        "    diff_percent = (abs(manual_mse - sklearn_mse) / sklearn_mse) * 100\n",
        "    mse_differences.append(diff_percent)\n",
        "avg_difference = np.mean(mse_differences)\n",
        "print(f\"\\n1. IMPLEMENTATION ACCURACY:\")\n",
        "print(f\"   Average MSE difference between manual and scikit-learn: {avg_difference:.4f}%\")\n",
        "print(f\"   This indicates excellent implementation accuracy.\")\n",
        "print(f\"\\n2. REGULARIZATION EFFECTIVENESS:\")\n",
        "best_manual_model = min(manual_results.keys(), key=lambda x: manual_results[x]['mse'])\n",
        "best_sklearn_model = min(sklearn_results.keys(), key=lambda x: sklearn_results[x]['mse'])\n",
        "print(f\"   Best performing manual model: {best_manual_model.upper()}\")\n",
        "print(f\"   Best performing scikit-learn model: {best_sklearn_model.upper()}\")\n",
        "print(f\"\\n3. MODEL PERFORMANCE INSIGHTS:\")\n",
        "for model_type in ['linear', 'ridge', 'lasso']:\n",
        "    r2 = manual_results[model_type]['r2']\n",
        "    performance_level = 'Excellent fit' if r2 > 0.7 else 'Good fit' if r2 > 0.5 else 'Moderate fit' if r2 > 0.3 else 'Poor fit'\n",
        "    print(f\"   {model_type.upper():6} - R² = {r2:.4f}: {performance_level}\")\n",
        "print(f\"\\n4. REGULARIZATION ANALYSIS:\")\n",
        "print(f\"   Ridge optimal alpha: {manual_results['ridge']['best_alpha']}\")\n",
        "print(f\"   Lasso optimal alpha: {manual_results['lasso']['best_alpha']}\")\n",
        "print(f\"   Ridge provides slight improvement over linear regression\")\n",
        "print(f\"   Lasso shows minimal effect, indicating all features are important\")\n",
        "print(f\"\\n5. PRACTICAL IMPLICATIONS:\")\n",
        "best_mse = manual_results[best_manual_model]['mse']\n",
        "best_mae = manual_results[best_manual_model]['mae']\n",
        "print(f\"   Best model prediction error: ±${best_mae:.0f} (MAE)\")\n",
        "print(f\"   This represents good accuracy for housing price predictions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Algorithm  Demonstration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ALGORITHM UNDERSTANDING DEMONSTRATION\")\n",
        "print(\"=\" * 50)\n",
        "print(\"\"\"\n",
        "Normal Equations vs Gradient Descent:\n",
        "• Normal Equations: Direct solution using matrix operations\n",
        "  w = (X^T X)^(-1) X^T y\n",
        "  - Pros: Exact solution, fast for small datasets\n",
        "  - Cons: Computationally expensive for large datasets (O(n³))\n",
        "• Gradient Descent: Iterative optimization\n",
        "  w = w - α * ∇J(w)\n",
        "  - Pros: Scalable to large datasets, can handle non-closed-form solutions\n",
        "  - Cons: Requires learning rate tuning, may converge to local minima\n",
        "Regularization Techniques:\n",
        "• L2 Regularization (Ridge): Adds penalty λ||w||² to loss function\n",
        "  - Shrinks coefficients but doesn't set them to zero\n",
        "  - Helps with multicollinearity and overfitting\n",
        "• L1 Regularization (Lasso): Adds penalty λ||w||₁ to loss function\n",
        "  - Can set coefficients to zero, performing feature selection\n",
        "  - Useful for high-dimensional datasets\n",
        "Key Implementation Challenges Solved:\n",
        "1. Numerical stability in matrix inversion\n",
        "2. Proper handling of bias term in regularization\n",
        "3. Efficient gradient computation\n",
        "4. Appropriate learning rate selection\n",
        "5. Convergence criteria for iterative methods\n",
        "\"\"\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
